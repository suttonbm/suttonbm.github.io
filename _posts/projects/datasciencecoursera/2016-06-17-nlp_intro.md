---
title: "Natural Language Processing"
date: 2016-06-20
author: suttonbm
layout: post
categories:
  - projects
tags:
  - coursera
  - data.science
  - R
project: datasciencecoursera.capstone
excerpt: >
  Reading notes for Natural Language Processing NLP
---



## Introduction
Today's goal is to take a look at the text corpus to be used in the capstone project, as well as to gain a working familiarity with natural language processing, or NLP.  Let's jump right in.

The baseline data to be used in the capstone is a corpus called [HC Corpora](http://www.corpora.heliohost.org/).  Coursera/JHU have kindly made available a zip file containing corpora from English, German, Russian, and Finnish.  Each corpus contains data from blogs, news, and twitter.  Data is provided in a raw form - just text.  Any analysis will require some sort of preprocessing before anything useful can be done with the data.

Small aside - I could see it being fun to repeat this whole project with a corpus of language derived from a show or something.  Would be fun to have a Captain Picard predictive keyboard...

## Alternative/Additional Corpora
There are quite a few additional corpora openly available on the web.  I'm not sure whether it will make sense to include these data in the analysis for this course.

#### Google Books
Google has some outrageously large quantity of books processed down into n-grams and available on the web for anyone to use.  I'm not sure how big the total corpus comes to, but I probably won't be making use of this just due to sheer size.
[Google N-Grams Corpus](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html)

#### American National Corpus
Another corpus that is a bit more reasonable in size is the American National Corpus, weighing in at 15 million words.  There's also a manually annotated corpus of 500,000 words available for use.
[Open ANC](http://www.anc.org/data/oanc/download/)
[MASC](http://www.anc.org/data/masc/downloads/)

#### Brigham Young Corpus
Brigham Young University also has a fairly large corpus freely available on the web:
[BYU Corpus](http://corpus.byu.edu/full-text/)

## Text Mining Preprocessing
Preparing for text mining or analysis of a selected corpus is roughly a three-step process:

  1. Obtain the data
  2. Preprocess the data
  3. Transform the data to a structured format

Preprocessing the data aims to prepare the raw data for transformation.  Some common preprocessing steps may include:

  * Whitespace removal
  * Stopword removal
  * Word stemming
  * Punctuation removal

Stopwords are defined as words which (generally) appear extremely frequently in the corpus and may provide little predictive information.  In other words, they appear in combination with many words, making it very difficult to do prediction with high accuracy.

Word stemming is essentially clustering words with identical meaning but different suffixes, prefixes, etc.  For example, "ducks" and "duck" would be categorized as the same word.

## Getting Started in R
There are multiple frameworks in R providing language processing functionality.  However, for now I'm going to explore the `tm` package.

> We present a text mining framework ... cetered around the new extension package `tm`.  This open source package ... provides the basic infrastructure necessary to organize, transform, and analyze textual data.
[1] "(Feinerer, Hornik, and Meyer, 2008)"

#### The Data...
I've created a sample data file containing the first 100 lines of the US news corpus from the [HC Corpora](http://www.corpora.heliohost.org/) for the express purpose of exploring the `tm` package's capabilities.  The whole corpus is quite large and would pose a challenge to quickly obtaining some example results.  The data I use below can be found on [Github](https://github.com/suttonbm/suttonbm.github.io/tree/master/_source/datasciencecoursera-capstone/en-US.news.sample.txt).

#### Reading the Data
Let's get started.  First thing to do is install packages:


```r
install.packages("tm")
```

Next, we need to read in the data to be analyzed.  The `tm` package provides many different interfaces for reading in data.  In this case, we're just reading in a plain text file.


```r
US.news <- file.path("data")
US.news
```

```
## [1] "data"
```

```r
library(tm)
newsCorp <- Corpus(DirSource(US.news))
```

We can do some quick examination of the created corpus:


```r
as.character(newsCorp[[1]])[1:3]
```

```
## [1] "In the years thereafter, most of the Oil fields and platforms were named after pagan gods."
## [2] "We love you Mr. Brown."
## [3] "Chad has been awesome with the kids and holding down the fort while I work later than usual! The kids have been busy together playing Skylander on the XBox together, after Kyan cashed in his $$$ from his piggy bank. He wanted that game so bad and used his gift card from his birthday he has been saving and the money to get it (he never taps into that thing either, that is how we know he wanted it so bad). We made him count all of his money to make sure that he had enough! It was very cute to watch his reaction when he realized he did! He also does a very good job of letting Lola feel like she is playing too, by letting her switch out the characters! She loves it almost as much as him."
```

The data has been read into a `Corpus` object.  The command above shows only the first three lines of the file.

#### Preprocessing Data
So now that our data is loaded into R, let's try some preprocessing.  The raw data may include extra whitespace or punctuation which could complicate or confuse the analysis.  Additionally, as discussed above, common words can be eliminated to simplify the dataset.

##### Removal of Punctuation

```r
newsCorp <- tm_map(newsCorp, removePunctuation)
as.character(newsCorp[[1]])[1:3]
```

```
## [1] "In the years thereafter most of the Oil fields and platforms were named after pagan gods."
## [2] "We love you Mr Brown"
## [3] "Chad has been awesome with the kids and holding down the fort while I work later than usual The kids have been busy together playing Skylander on the XBox together after Kyan cashed in his  from his piggy bank He wanted that game so bad and used his gift card from his birthday he has been saving and the money to get it he never taps into that thing either that is how we know he wanted it so bad We made him count all of his money to make sure that he had enough It was very cute to watch his reaction when he realized he did He also does a very good job of letting Lola feel like she is playing too by letting her switch out the characters She loves it almost as much as him"
```

##### Removal of Stopwords and Numbers

```r
newsCorp <- tm_map(newsCorp, removeWords, stopwords('english'))
newsCorp <- tm_map(newsCorp, removeNumbers)
as.character(newsCorp[[1]])[1:3]
```

```
## [1] "In  years thereafter    Oil fields  platforms  named  pagan gods."
## [2] "We love  Mr Brown"
## [3] "Chad   awesome   kids  holding   fort  I work later  usual The kids   busy together playing Skylander   XBox together  Kyan cashed      piggy bank He wanted  game  bad  used  gift card   birthday    saving   money  get   never taps   thing either     know  wanted   bad We made  count    money  make sure    enough It   cute  watch  reaction   realized   He also    good job  letting Lola feel like   playing   letting  switch   characters She loves  almost  much  "
```

##### Apply Stemming, Convert to Lowercase

```r
newsCorp <- tm_map(newsCorp, stemDocument)
newsCorp <- tm_map(newsCorp, tolower)
as.character(newsCorp[[1]])[1:3]
```

```
## [1] "in  year thereaft    oil field  platform  name  pagan gods."
## [2] "we love  mr brown"
## [3] "chad   awesom   kid  hold   fort  i work later  usual the kid   busi togeth play skyland   xbox togeth  kyan cash      piggi bank he want  game  bad  use  gift card   birthday    save   money  get   never tap   thing either     know  want   bad we made  count    money  make sure    enough it   cute  watch  reaction   realiz   he also    good job  let lola feel like   play   let  switch   charact she love  almost  much "
```

##### Removing Extra Whitespace

```r
newsCorp <- tm_map(newsCorp, stripWhitespace)
as.character(newsCorp[[1]])[1:3]
```

```
## [1] "in year thereaft oil field platform name pagan gods."
## [2] "we love mr brown"
## [3] "chad awesom kid hold fort i work later usual the kid busi togeth play skyland xbox togeth kyan cash piggi bank he want game bad use gift card birthday save money get never tap thing either know want bad we made count money make sure enough it cute watch reaction realiz he also good job let lola feel like play let switch charact she love almost much "
```

### References
<p><a id='bib-JSSv025i05'></a><a href="#cite-JSSv025i05">[1]</a><cite>
I. Feinerer, K. Hornik and D. Meyer.
&ldquo;Text Mining Infrastructure in R&rdquo;.
In: <em>Journal of Statistical Software</em> 25.1 (2008), pp. 1&ndash;54.
ISSN: 1548-7660.
DOI: <a href="http://dx.doi.org/10.18637/jss.v025.i05">10.18637/jss.v025.i05</a>.
URL: <a href="https://www.jstatsoft.org/index.php/jss/article/view/v025i05">https://www.jstatsoft.org/index.php/jss/article/view/v025i05</a>.</cite></p>
